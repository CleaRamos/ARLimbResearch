# ARLimbResearch
This project simulates limb movement in XR for amputees by translating muscle sensor data into virtual limb motions.

#  Overview
Machine learning (ML) has enabled wearable devices to recognize hand gestures from surface electromyography (sEMG) signals. These devices create a new paradigm of human-computer interaction in extended reality (XR), which could be extended to the disabled group, particularly amputees with healthy muscles. This project explores how this technology can enable amputees to interact in XR and control digital devices in real life by investigating how to map the sEMG signals of an amputee to the target actions in VR and control sequences of a digital device.

This project will investigate the question in three phases. First, since no commercial product is available, the PI will work closely with Bucknell undergraduate students to develop a sEMG controller prototype. Current research prototype often uses a circular grid of 12 to 32 sEMG sensors. To obtain an optimal design, the research team will study and assess the number of required sensors and the best placement locations by quantifying the “independence-ness” of the signals using spectrum analysis. Next, the team will recruit participants (amputees with healthy muscles) via local connection Geisinger, create XR experiences for data collection, and use the collected data to train an ML model specifically for amputees. The team will also conduct a user study using a Likert scale questionnaire and task-based accuracy measurement in XR to evaluate the design. Based on the feedback of the user study, in the last phase, the researchers will refine and optimize the design for real-life applications.

#  Project Goals

## Phase 1
The phase has two sub-phases, and the research questions of this phase are: 
1. How many sensors do we need to capture the hand movement completely?
2. Where are the optical locations of these sensors? 
3. What machine learning models perform better?
4. What's the performance of using spectrum analysis to create a decision tree?
5. Will a hybrid approach outperform logic-based signal analysis or data-driven machine learning? [Note: Many meaningful research studies nowadays are hybrid! Solely machine learning usually has excellent results but few insights into the issues.]
[I believe it is implicitly included in Q1-2] How different are these signals among different people?


### Phase 1a - Prototype Development

### Phase 1b - Optimal Design Investigation

## Phase 2 - Refinement for Amputees

## Phase 3 - Applications





## 
Overview



## h1
Overview
